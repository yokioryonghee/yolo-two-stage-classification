# app.py
import os
import time
import threading
from pathlib import Path
from typing import Dict, Tuple, Optional

import av
import cv2
import numpy as np
import requests
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from ultralytics import YOLO

# ======================
# CONFIG (ìˆ˜ì • í¬ì¸íŠ¸)
# ======================
DETECT_WEIGHTS = "yolov8n.pt"          # Ultralytics ê¸°ë³¸ íƒì§€ ê°€ì¤‘ì¹˜
CLASSIFY_WEIGHTS = "yolov8n-cls.pt"    #íŠœë‹ëœ ê°€ì¤‘ì¹˜ íŒŒì¼

# (ì²˜ìŒ ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œí•  URL) â€” ì•„ë˜ 2ê°œ ì¤‘ ìµœì†Œ C L S ëŠ” ê¼­ ì±„ìš°ê¸°
WEIGHTS_URL_DET = "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt"
WEIGHTS_URL_CLS = "https://github.com/yokioryonghee/yolo-two-stage-classification/releases/download/yolov8n-cls.pt/yolov8n-cls.pt"  # â† ë„ˆì˜ Release URLë¡œ ë°”ê¾¸ê¸°

CONF_THRES = 0.35
TARGET_CLASSES = {"car", "truck", "bus"}  # íƒì§€ ë‹¨ê³„ì—ì„œ ë¶„ë¥˜ê¸°ë¡œ ë³´ë‚¼ ëŒ€ìƒ

# WebRTC (TURN ê¶Œì¥)
RTC_CONFIG = RTCConfiguration({
    "iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        # {"urls": ["turn:YOUR_TURN_HOST:3478"], "username": "user", "credential": "pass"},
    ]
})

# ======================
# UTIL: ê°€ì¤‘ì¹˜ ìë™ ë‹¤ìš´ë¡œë“œ
# ======================
def download_if_missing(path: str, url: str, chunk: int = 1 << 14):
    if not url or os.path.exists(path):
        return
    try:
        print(f"[weights] downloading {path} from {url} ...")
        with requests.get(url, stream=True, timeout=60) as r:
            r.raise_for_status()
            with open(path, "wb") as f:
                for c in r.iter_content(chunk_size=chunk):
                    if c:
                        f.write(c)
        print(f"[weights] saved -> {path}")
    except Exception as e:
        print(f"[weights] warn: could not fetch {url} ({e}). Place '{path}' manually.")

download_if_missing(DETECT_WEIGHTS, WEIGHTS_URL_DET)
download_if_missing(CLASSIFY_WEIGHTS, WEIGHTS_URL_CLS)

# ======================
# GLOBAL (room í”„ë ˆì„ ì €ì¥)
# ======================
ROOM_FRAMES: Dict[str, Tuple[np.ndarray, float]] = {}
ROOM_LOCK = threading.Lock()

# ======================
# MODEL LOAD
# ======================
@st.cache_resource(show_spinner=False)
def load_models():
    det = YOLO(DETECT_WEIGHTS)        # 1ë‹¨ê³„: íƒì§€
    cls = YOLO(CLASSIFY_WEIGHTS)      # 2ë‹¨ê³„: âœ… ë„¤ íŠœë‹ ë¶„ë¥˜ê¸°
    return det, cls

det_model, cls_model = load_models()

# ======================
# INFERENCE: íƒì§€ â†’ ë¶„ë¥˜ â†’ í‘œê¸°
# ======================
def two_stage_annotate(frame_bgr: np.ndarray) -> np.ndarray:
    vis = frame_bgr.copy()
    det_res = det_model.predict(source=frame_bgr, imgsz=640, conf=CONF_THRES, verbose=False)

    crops, boxes = [], []
    for r in det_res:
        names = r.names or {}
        if r.boxes is None:
            continue
        for b in r.boxes:
            cls_id = int(b.cls[0])
            cls_name = names.get(cls_id, str(cls_id))
            if cls_name in TARGET_CLASSES:
                x1, y1, x2, y2 = map(int, b.xyxy[0].cpu().numpy())
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(frame_bgr.shape[1]-1, x2), min(frame_bgr.shape[0]-1, y2)
                if x2 > x1 and y2 > y1:
                    crop = frame_bgr[y1:y2, x1:x2]
                    if crop.size > 0:
                        crops.append(((x1, y1, x2, y2), crop))
                        boxes.append((x1, y1, x2, y2))

    labels = {}
    if crops:
        batch = [cv2.cvtColor(c, cv2.COLOR_BGR2RGB) for _, c in crops]
        cls_res = cls_model.predict(source=batch, imgsz=224, verbose=False)
        for (xyxy, _), cr in zip(crops, cls_res):
            top1 = int(cr.probs.top1)
            name = cr.names.get(top1, str(top1))
            confp = float(cr.probs.top1conf)
            labels[xyxy] = f"{name} ({confp:.2f})"

    for (x1, y1, x2, y2) in boxes:
        label = labels.get((x1, y1, x2, y2), "vehicle")
        cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(vis, label, (x1, max(20, y1 - 6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)
    return vis

# ======================
# UI
# ======================
st.set_page_config(page_title="YOLO Two-Stage (iPhoneâ†’Laptop, WebRTC)", layout="wide")
st.title("ğŸš— YOLO Two-Stage: iPhone Camera â†’ Server â†’ Laptop (WebRTC)")

missing = [p for p in [DETECT_WEIGHTS, CLASSIFY_WEIGHTS] if not Path(p).exists()]
if missing:
    st.error(f"Missing weights: {missing}\n- Set auto-download URLs or place files in project root.")
    st.stop()

with st.sidebar:
    st.header("Settings")
    st.write("â€¢ iPhone Safari/Chromeì—ì„œ ì´ í˜ì´ì§€ ì ‘ì† â†’ Broadcast íƒ­ â†’ ì¹´ë©”ë¼ í—ˆìš©")
    st.write("â€¢ HTTPS ê¶Œì¥(í•„ìˆ˜), ì•ˆì •ì„± ìœ„í•´ TURN ì„œë²„ ì¶”ì²œ")
    room_id = st.text_input("Room ID (iPhone & Laptop ë™ì¼í•˜ê²Œ)", value="demo")

tabs = st.tabs(["ğŸ“± Broadcast (iPhone)", "ğŸ’» View (Laptop)"])

# ---- iPhone: ë°©ì†¡ ----
with tabs[0]:
    st.subheader("ğŸ“± Broadcast")
    st.write("iPhoneì—ì„œ ì´ íƒ­ì„ ì—´ê³  **ì¹´ë©”ë¼ í—ˆìš©** í›„ ì‹œì‘í•˜ì„¸ìš”.")

    def publisher_callback(frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        # ì„±ëŠ¥ í•„ìš” ì‹œ ë‹¤ìš´ìŠ¤ì¼€ì¼: img = cv2.resize(img, (640, int(img.shape[0]*640/img.shape[1])))
        out = two_stage_annotate(img)
        with ROOM_LOCK:
            ROOM_FRAMES[room_id] = (out, time.time())
        return av.VideoFrame.from_ndarray(out, format="bgr24")

    webrtc_streamer(
        key=f"pub:{room_id}",
        mode=WebRtcMode.SENDRECV,  # iPhone í™”ë©´ì—ë„ ì£¼ì„ ê²°ê³¼ í‘œì‹œ
        rtc_configuration=RTC_CONFIG,
        media_stream_constraints={"video": True, "audio": False},
        video_frame_callback=publisher_callback,
    )

# ---- ë…¸íŠ¸ë¶: ì‹œì²­ ----
with tabs[1]:
    st.subheader("ğŸ’» View")
    st.write("ë…¸íŠ¸ë¶ì—ì„œëŠ” ê°™ì€ Room IDë¥¼ ì…ë ¥í•˜ê³  ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì‹œì²­í•˜ì„¸ìš”.")
    start = st.button("ë·° ì‹œì‘")
    stop = st.button("ë·° ì •ì§€")
    if "viewing" not in st.session_state:
        st.session_state.viewing = False
    if start: st.session_state.viewing = True
    if stop:  st.session_state.viewing = False

    canvas = st.empty()
    info = st.empty()

    if st.session_state.viewing:
        while st.session_state.viewing:
            frame: Optional[np.ndarray] = None
            ts = 0.0
            with ROOM_LOCK:
                if room_id in ROOM_FRAMES:
                    frame, ts = ROOM_FRAMES[room_id]
            if frame is None:
                info.warning("ëŒ€ê¸° ì¤‘â€¦ iPhone íƒ­ì—ì„œ Broadcastë¥¼ ì‹œì‘í•˜ê³  ì¹´ë©”ë¼ë¥¼ í—ˆìš©í•˜ì„¸ìš”.")
                time.sleep(0.3)
                continue
            canvas.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB", use_column_width=True)
            info.caption(f"room_id = {room_id} | last update: {time.strftime('%H:%M:%S', time.localtime(ts))}")
            time.sleep(0.03)
